{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ],
      "metadata": {
        "id": "E2SBeBxoki9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/drive/1rF9inkLhxMNejXL8bW-ESX_cVAEct1-6\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelpandas/blob/main/notebooks/blip-auto-captions.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "metadata": {
        "id": "4OcARTFek9Sv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# _**Auto-Generating Captions for Images and Uploading to Labelbox**_"
      ],
      "metadata": {
        "id": "9ImuMsq4kvID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Hugging Face library for BLIP and Labelbox connectors"
      ],
      "metadata": {
        "id": "Nh4NB8ZRL2is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q # Installing Hugging Face BLIP model libraries\n",
        "!pip install labelpandas --upgrade -q # LabelPandas allows us to easily with DataFrames"
      ],
      "metadata": {
        "id": "2PXSjmmJOP6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Labelbox/labelpandas -q # For this demo, we will get images from the LabelPandas GitHub repo"
      ],
      "metadata": {
        "id": "fYAeHFQWjJ_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide a Labelbox API key and source data to generate captions for"
      ],
      "metadata": {
        "id": "R0vevfTdL78Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"\" # Labelbox API Key\n",
        "csv_path = \"https://raw.githubusercontent.com/Labelbox/labelpandas/main/datasets/blip-images.csv\" # Path to your CSV file"
      ],
      "metadata": {
        "id": "664aI3H1z4nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read CSV data to Pandas DataFrame"
      ],
      "metadata": {
        "id": "cV0EM99SNYhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "AZ41fxwqOcIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(csv_path) # Load in your CSV as a Pandas DataFrame\n",
        "df.head()"
      ],
      "metadata": {
        "id": "mW1atZRhNabP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load local files to Labelbox URLs"
      ],
      "metadata": {
        "id": "7YCv8Z2Hj61N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import labelpandas as lp"
      ],
      "metadata": {
        "id": "7m-B2l2DkAoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = lp.Client(api_key)"
      ],
      "metadata": {
        "id": "S53D-vVqj-t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load local files as Labelbox URLs\n",
        "df = lp.load_local_files(\n",
        "    client=client,\n",
        "    table=df, \n",
        "    file_path_column=\"file_path\",\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "KsQj3dnEj9Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code will add model-generated text captions as columns to a DataFrame of image URLs"
      ],
      "metadata": {
        "id": "XQIjjNOvMyTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "\n",
        "def process_batch(batch, processor, model):\n",
        "    \"\"\" Given a data row, returns a Pandas DataFrame-ready row as-a-dictionary with global key, row data URL, and caption metadata values\n",
        "    Args:\n",
        "        batch       :   List of dictionaries with \"row_data\" and \"global_key\" keys\n",
        "        processor   :   BlipProcessor object\n",
        "        model       :   BlipForConditionalGeneration object\n",
        "    Returns:\n",
        "        List of dictionaries with keys \"row_data\", \"global_key\" and two metadata columns for conditional and unconditional caption\n",
        "    \"\"\"  \n",
        "    # Download images from local files\n",
        "    images = [Image.open(x[\"file_path\"]) for x in batch]\n",
        "    # Conditional (prime the model with a text prefix)\n",
        "    conditional_inputs = processor(images=images, text=[\"a picture of\"]*len(images), add_special_tokens=True, truncation=True, padding=True, return_tensors=\"pt\") # Encode the images\n",
        "    conditional_outputs = model.generate(**conditional_inputs) # Run model\n",
        "    conditional_captions = [processor.decode(output, skip_special_tokens=True) for output in conditional_outputs] # Decode model output\n",
        "    # Unconditional\n",
        "    unconditional_inputs = processor(images=images, add_special_tokens=True, truncation=True, padding=True, return_tensors=\"pt\") # Encode the images\n",
        "    unconditional_outputs = model.generate(**unconditional_inputs) # Run model\n",
        "    unconditional_captions = [processor.decode(output, skip_special_tokens=True) for output in unconditional_outputs] # Decode model output    \n",
        "\n",
        "    data_list = [{\n",
        "        \"global_key\": batch[i][\"global_key\"], \"row_data\": batch[i][\"row_data\"],\n",
        "        \"metadata///string///unconditional_caption\": unconditional_captions[i],\n",
        "        \"metadata///string///conditional_caption\": conditional_captions[i]\n",
        "    } for i in range(0, len(images))]\n",
        "    \n",
        "    return data_list\n",
        "\n",
        "def generate_captions_for_data_rows(dataframe, batch_size=16):\n",
        "    \"\"\" Creates captions from data rows and returns a Pandas DataFrame\n",
        "    Args:\n",
        "        api_key         : Required (str) - Labeblox API key\n",
        "        dataframe       : Required (pandas.core.frame.DataFrame) - Pandas DataFrame \n",
        "        batch_size      : Optional (int) - Number of images to process at a time\n",
        "    Returns:\n",
        "        Pandas DataFrame with model-generated captions as metadata string values \n",
        "    \"\"\"  \n",
        "    table_dict = dataframe.to_dict('records') # Convert DataFrame to list of dictionary rows\n",
        "\n",
        "    # Download blip model which generates text captions for images\n",
        "    print(f'Downloading BLIP model')\n",
        "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\", return_tensors=\"pt\") # Get your processor object from hugging face\n",
        "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\") # Get your pretrained model object from hugging face\n",
        "\n",
        "    batch_num = len(table_dict) // batch_size if len(table_dict) % batch_size == 0 else (len(table_dict) // batch_size) + 1\n",
        "    print(f'Downloading, encoding and creating predictions for data rows in {batch_num} batches of batch size {batch_size}')\n",
        "\n",
        "    # Loop through your data rows as batches to craete a list of dictionaries where { key = column_name : value = row_value }\n",
        "    data = []\n",
        "    for i in tqdm(range(0, len(table_dict), batch_size), total=batch_num):\n",
        "        res = process_batch(table_dict[i:i+batch_size], processor, model)\n",
        "        data.extend(res)\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    print(f'Success: captions generated')  \n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "Hp4csQxoF297"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = generate_captions_for_data_rows(df) # Run the above code, generating captions for images"
      ],
      "metadata": {
        "id": "QJ-ov0xnF9OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "aNW6HRGAQyEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload your Data Row DataFrame to Labelbox, including the model-generated captions as metadata"
      ],
      "metadata": {
        "id": "O0kY8vZMO-bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Labelbox dataset to upload data rows to\n",
        "dataset = client.lb_client.create_dataset(name=\"blip-augment-data-search-demo\")\n",
        "\n",
        "# Create data rows using LabelPandas\n",
        "results = client.create_data_rows_from_table(\n",
        "    table = df,\n",
        "    dataset_id = dataset.uid,\n",
        "    skip_duplicates = False, \n",
        "    verbose = True\n",
        ")"
      ],
      "metadata": {
        "id": "Kbtoxiax5r55"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}